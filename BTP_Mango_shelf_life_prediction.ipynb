{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1641cca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f831b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "input_dir=\"C:\\\\Users\\\\91773\\\\Desktop\\\\Mangoes to be cropped\"\n",
    "output_dir=\"C:\\\\Users\\\\91773\\\\Desktop\\\\Cropped Mangoes\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ca056",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count=0\n",
    "for file_name in os.listdir(input_dir):\n",
    "    file_path=os.path.join(input_dir, file_name)\n",
    "    img=cv2.imread(file_path)\n",
    "    file_name=file_name.split('_')[2].split('.')[0]\n",
    "    res1=img[90:700,0:550]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res1)\n",
    "    res2=img[710:1165,0:550]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res2)\n",
    "    res3=img[1170:1700,0:650]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res3)\n",
    "    res4=img[0:675,550:1400]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res4)\n",
    "    res5=img[675:1200,550:1300]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res5)\n",
    "    res6=img[1170:1760,630:1410]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res6)\n",
    "    res7=img[0:600,1410:2200]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res7)\n",
    "    res8=img[580:1300,1310:2200]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res8)\n",
    "    res9=img[1250:1750,1400:2200]\n",
    "    count+=1\n",
    "    cnt=str(count)\n",
    "    cv2.imwrite(output_dir+file_name+cnt+\".png\", res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d2aa0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_image(image):\n",
    "    res1=image[90:700,0:550]\n",
    "    res2=image[710:1165,0:550]\n",
    "    res3=image[1170:1700,0:650]\n",
    "    res4=image[0:675,550:1400]\n",
    "    res5=image[675:1200,550:1300]\n",
    "    res6=image[1170:1760,630:1410]\n",
    "    res7=image[0:600,1410:2200]\n",
    "    res8=image[580:1300,1310:2200]\n",
    "    res9=image[1250:1750,1400:2200]\n",
    "    li=[]\n",
    "    li.append(res1)\n",
    "    li.append(res2)\n",
    "    li.append(res3)\n",
    "    li.append(res4)\n",
    "    li.append(res5)\n",
    "    li.append(res6)\n",
    "    li.append(res7)\n",
    "    li.append(res8)\n",
    "    li.append(res9)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9649cfa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feature_extraction(img):\n",
    "    # Calculate the histogram of the image\n",
    "    li=[]\n",
    "    b, g, r=cv2.split(img)\n",
    "    li.append(b.mean())\n",
    "    li.append(g.mean())\n",
    "    li.append(r.mean())\n",
    "    hist, _ = np.histogram(img, bins=256)\n",
    "    \n",
    "    # Normalize the histogram to have values between 0 and 1\n",
    "    hist_norm = hist / (img.shape[0] * img.shape[1])\n",
    "    \n",
    "    # Calculate the entropy of the image\n",
    "    entropy = -np.sum(hist_norm * np.log2(hist_norm + 1e-7))\n",
    "    li.append(entropy)\n",
    "    # Print the entropy of the image\n",
    "    #print(\"Entropy: \", entropy)\n",
    "    \n",
    "    # Convert the image from BGR to RGB color space\n",
    "    img1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert the RGB image to HSI color space\n",
    "    hsi_img = cv2.cvtColor(img1, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Split the HSI image into its components\n",
    "    hue, sat, intensity = cv2.split(hsi_img)\n",
    "    \n",
    "    # Calculate the mean values of the hue, saturation, and intensity channels\n",
    "    hue_mean = np.mean(hue)\n",
    "    sat_mean = np.mean(sat)\n",
    "    intensity_mean = np.mean(intensity)\n",
    "    li.append(hue_mean)\n",
    "    li.append(sat_mean)\n",
    "    li.append(intensity_mean)\n",
    "    # Print the HSI values of the image\n",
    "    #print(\"Hue: \", hue_mean)\n",
    "    #print(\"Saturation: \", sat_mean)\n",
    "    #print(\"Intensity: \", intensity_mean)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    r = img[:,:,2]\n",
    "    r = cv2.GaussianBlur(r, (0,0), 7)\n",
    "    \n",
    "    # Binarize red channel using mean threshold\n",
    "    red_avg = np.mean(r[r != 0])\n",
    "    dark_spots = r.copy()\n",
    "    dark_spots[dark_spots > red_avg] = 0\n",
    "    dark_spots = cv2.threshold(dark_spots, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Extract saturation channel from HSV and use as metric for light spots\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    s = hsv[:,:,1]\n",
    "    s_avg = np.mean(s[s != 0])\n",
    "    light_spots = s.copy()\n",
    "    light_spots[light_spots > 0.7*s_avg] = 0\n",
    "    light_spots = cv2.threshold(light_spots, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Combine dark and light spots and process\n",
    "    spots = cv2.bitwise_or(dark_spots, light_spots)\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    mask[16:-16,16:-16] = 1\n",
    "    mask = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (16,16)))\n",
    "    spots = cv2.bitwise_and(spots, cv2.bitwise_not(mask))\n",
    "    spots = cv2.dilate(spots, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2,2)))\n",
    "    contours, hierarchy = cv2.findContours(spots, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Remove calyx and small segments\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < 40:\n",
    "            continue\n",
    "        epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        if len(approx) < 5:\n",
    "            continue\n",
    "        ellipse = cv2.fitEllipse(approx)\n",
    "        center = ellipse[0]\n",
    "        axes = ellipse[1]\n",
    "        roundness = axes[0] / axes[1]\n",
    "        if roundness < 0.1:\n",
    "            continue\n",
    "        dist = np.sqrt((500-center[0])**2 + (500-center[1])**2)\n",
    "        if dist < 85 or area / np.sum(mask) < 0.03:\n",
    "            cv2.drawContours(spots, [cnt], -1, 0, -1)\n",
    "    \n",
    "    # Compute percent blemished\n",
    "    percent_blemished = (np.sum(spots != 0) / np.sum(mask))*100\n",
    "    li.append(percent_blemished)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d37528",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_dir_grade1=\"C:\\\\Users\\\\91773\\\\Desktop\\\\G1\"\n",
    "img_dir_grade2=\"C:\\\\Users\\\\91773\\\\Desktop\\\\G2\"\n",
    "img_dir_grade3=\"C:\\\\Users\\\\91773\\\\Desktop\\\\G3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca22e1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels = [\"G1\", \"G2\", \"G3\"]\n",
    "columns=['Blue Component','Green Component','Red Component','Entropy','Hue','Saturation','Intensity','Percent Defect','Grade']\n",
    "df=pd.DataFrame(columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac272654",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for img in os.listdir(img_dir_grade1):\n",
    "    file_path=os.path.join(img_dir_grade1, img)\n",
    "    img=cv2.imread(file_path)\n",
    "    feature=feature_extraction(img)\n",
    "    feature.append(\"G1\")\n",
    "    new_df=pd.DataFrame([feature],columns=df.columns)\n",
    "    new_df['Percent Defect']=new_df['Percent Defect']\n",
    "    df=pd.concat([df, new_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d3612",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[df['Grade']==\"G1\"]['Green Component'].mean(), df[df['Grade']==\"G1\"]['Red Component'].mean(), df[df['Grade']==\"G1\"]['Blue Component'].mean(), df[df['Grade']==\"G1\"]['Percent Defect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0ef19",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for img in os.listdir(img_dir_grade2):\n",
    "    file_path=os.path.join(img_dir_grade2, img)\n",
    "    img=cv2.imread(file_path)\n",
    "    feature=feature_extraction(img)\n",
    "    feature.append(\"G2\")\n",
    "    new_df=pd.DataFrame([feature],columns=df.columns)\n",
    "    new_df['Percent Defect']=new_df['Percent Defect']\n",
    "    df=pd.concat([df, new_df], ignore_index=True)\n",
    "df[df['Grade']=='G2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fdda8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[df['Grade']=='G2']['Green Component'].mean(), df[df['Grade']=='G2']['Red Component'].mean(), df[df['Grade']=='G2']['Blue Component'].mean(),  df[df['Grade']=='G2']['Percent Defect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d5813",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for img in os.listdir(img_dir_grade3):\n",
    "    file_path=os.path.join(img_dir_grade3, img)\n",
    "    img=cv2.imread(file_path)\n",
    "    feature=feature_extraction(img)\n",
    "    feature.append(\"G3\")\n",
    "    new_df=pd.DataFrame([feature],columns=df.columns)\n",
    "    df=pd.concat([df, new_df], ignore_index=True)\n",
    "df[df['Grade']=='G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfcf2b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[df['Grade']=='G3']['Green Component'].mean(), df[df['Grade']=='G3']['Red Component'].mean(), df[df['Grade']=='G3']['Blue Component'].mean(),  df[df['Grade']=='G3']['Percent Defect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6d684",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "num_epochs=81\n",
    "model.fit(X_train, pd.get_dummies(y_train), epochs=num_epochs, batch_size=10)\n",
    "\n",
    "# Testing the model\n",
    "_, accuracy = model.evaluate(X_test, pd.get_dummies(y_test))\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452446ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "Y_pred = np.array([labels[idx] for idx in np.argmax(y_pred, axis=1)])\n",
    "cm=confusion_matrix(y_test, Y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4e8bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_1=pd.DataFrame(columns=columns[:-1])\n",
    "images_path=\"C:\\\\Users\\\\91773\\\\Downloads\\\\output_data\\\\\"\n",
    "image=cv2.imread(images_path+\"2021-08-11 06_55_00.png\")\n",
    "images_list=split_image(image)\n",
    "for i in images_list:\n",
    "    feat=feature_extraction(i)\n",
    "    newdf=pd.DataFrame([feat],columns=columns[:-1])\n",
    "    df_1=pd.concat([df_1,newdf], ignore_index=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762235c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_():\n",
    "    X_pred=df_1\n",
    "    grade_predicted=model.predict(X_pred)\n",
    "    predicted_labels = np.array([labels[idx] for idx in np.argmax(grade_predicted, axis=1)])\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729ee46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count={'day1':{\"G1\":0,\"G2\":0,\"G3\":0},'day2':{\"G1\":0,\"G2\":0,\"G3\":0},'day3':{\"G1\":0,\"G2\":0,\"G3\":0},'day4':{\"G1\":0,\"G2\":0,\"G3\":0},'day5':{\"G1\":0,\"G2\":0,\"G3\":0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698e7d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions=predict_()\n",
    "for g in predictions:\n",
    "    if g==\"G1\":\n",
    "        count['day2'][\"G1\"]+=1\n",
    "    elif g==\"G2\":\n",
    "        count['day2'][\"G2\"]+=1\n",
    "    elif g==\"G3\":\n",
    "        count['day2'][\"G3\"]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cd2e2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count['day1'][\"G1\"], count['day1'][\"G2\"], count['day1'][\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0756f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count['day2'][\"G1\"], count['day2'][\"G2\"], count['day2'][\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192155f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count['day3'][\"G1\"], count['day3'][\"G2\"], count['day3'][\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebd84d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count['day4'][\"G1\"], count['day4'][\"G2\"], count['day4'][\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3852bdb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count['day5'][\"G1\"], count['day5'][\"G2\"], count['day5'][\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a361682",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g1=[]\n",
    "g2=[]\n",
    "g3=[]\n",
    "g1.append(count['day1'][\"G1\"])\n",
    "g1.append(count['day2'][\"G1\"])\n",
    "g1.append(count['day3'][\"G1\"])\n",
    "g1.append(count['day4'][\"G1\"])\n",
    "g1.append(count['day5'][\"G1\"])\n",
    "g2.append(count['day1'][\"G2\"])\n",
    "g2.append(count['day2'][\"G2\"])\n",
    "g2.append(count['day3'][\"G2\"])\n",
    "g2.append(count['day4'][\"G2\"])\n",
    "g2.append(count['day5'][\"G2\"])\n",
    "g3.append(count['day1'][\"G3\"])\n",
    "g3.append(count['day2'][\"G3\"])\n",
    "g3.append(count['day3'][\"G3\"])\n",
    "g3.append(count['day4'][\"G3\"])\n",
    "g3.append(count['day5'][\"G3\"])\n",
    "g1,g2,g3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6602ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x=[\"Week0\", \"Week1\", \"Week2\", \"Week3\", \"Week4\"]\n",
    "plt.plot(x,g1,label='g1')\n",
    "plt.plot(x,g2,label='g2')\n",
    "plt.plot(x,g3,label='g3')\n",
    "plt.title(\"Weekly Degradation Trend\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# We Define Shelf Life of a batch of mango in terms of its economic value in the market. Empirically Speaking, It is defined as the point in time where the number of g3 mangoes (The ones which cannot be sold) exceed the number of g2 mangoes (The ones which can be sold at some discounted price atleast), Since the batch is then believed to have lost the market value. Thus the transport has to take place before this time period, which in our case lies just before the end of 3rd week, i.e, somewhere around 18-20 days."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
